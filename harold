#!/usr/bin/env bash
# 2025
# Harold
# GitHub handle: seqinfomics

set -eo pipefail

# suppress platform echo when only --version/-V is requested
SUPPRESS_PLATFORM_ECHO=0
if [[ $# -eq 1 && ( "$1" == "-V" || "$1" == "--version" ) ]]; then
  SUPPRESS_PLATFORM_ECHO=1
fi

# decide trigger
trigger="mtime"
# trigger="input"
# trigger="code"

##########################################################################################
# functions
##########################################################################################

function get_git_commitid_tag() {
  cd $1
  gid=$(git rev-parse HEAD)
  tag=$(git describe --tags $gid 2>/dev/null || echo "No Tags")
  echo -ne "$gid\t$tag"
}

# determine if the platform is biowulf, FRCE, or something else and use modules accordingly
function get_platform() {
  if command -v scontrol &> /dev/null ; then
    platform=$(scontrol show config | grep ClusterName | sed 's/.*= //')
  else
    platform="unknown"
  fi
  echo $platform
}

# check if file exists and is readable
function check_file() {
  if [ ! -f $1 ]; then
    echo "File $1 does not exist!"
    exit 1
  fi
  if [ ! -r $1 ]; then
    echo "File $1 is not readable!"
    exit 1
  fi
}

# warn users if shared sif images are missing so they know a pull will occur
function warn_missing_shared_sifs() {
  local cfg_file="$1"
  local sif_dir="$2"
  if [[ ! -f "$cfg_file" ]]; then
    return
  fi
  if [[ ! -d "$sif_dir" ]]; then
    echo "WARNING: Requested Apptainer/Singularity image directory \"$sif_dir\" does not exist."
    return
  fi
  python - "$cfg_file" "$sif_dir" <<'PY'
import hashlib
import pathlib
import sys

cfg = pathlib.Path(sys.argv[1])
sif_dir = pathlib.Path(sys.argv[2])

def collect_containers(path: pathlib.Path):
    containers = {}
    lines = path.read_text().splitlines()
    capture = False
    indent = None
    for line in lines:
        if not capture:
            if line.strip().startswith("containers:"):
                capture = True
                indent = len(line) - len(line.lstrip())
            continue
        stripped = line.strip()
        if not stripped or stripped.startswith("#"):
            continue
        cur_indent = len(line) - len(line.lstrip())
        if cur_indent <= indent:
            break
        if ":" not in line:
            continue
        key, value = line.split(":", 1)
        value = value.split("#", 1)[0].strip()
        if not value:
            continue
        if value[0] in "\"'":
            quote = value[0]
            if value.endswith(quote):
                value = value[1:-1]
            else:
                value = value[1:]
        containers[key.strip()] = value
    return containers

try:
    containers = collect_containers(cfg)
except Exception:
    sys.exit(0)

missing = []
for key, image in containers.items():
    if "://" not in image:
        continue
    digest = hashlib.md5(image.encode()).hexdigest()
    found = False
    for ext in (".sif", ".simg"):
        candidate = sif_dir / f"{digest}{ext}"
        if candidate.exists():
            found = True
            break
    if not found:
        missing.append((key, image, digest))

if missing:
    print(f"WARNING: One or more shared Apptainer images are not staged under {sif_dir}", file=sys.stderr)
    for key, image, digest in missing:
        print(f"  - {key}: {image}", file=sys.stderr)
        print(f"    Expected digest filename {digest}.sif/.simg; will pull to /scratch/$USER/singularity on demand.", file=sys.stderr)
PY
}


##########################################################################################
# initial setup
##########################################################################################

# set PIPELINE_HOME
PIPELINE_HOME=$(readlink -f $(dirname "$0"))

# set snakefile
SNAKEFILE="${PIPELINE_HOME}/workflow/Snakefile"
check_file $SNAKEFILE

# get github commit tag
GIT_COMMIT_TAG=$(get_git_commitid_tag $PIPELINE_HOME)
if [[ $SUPPRESS_PLATFORM_ECHO -eq 0 ]]; then
  echo "$PLATFORM"
fi

# pipeline version file
VERSIONFILE="${PIPELINE_HOME}/VERSION"
check_file $VERSIONFILE
VERSION=$(cat $VERSIONFILE | head -n 1 | awk '{print $1}')

##########################################################################################
# Some more set up
##########################################################################################

PYTHONVERSION="3.11"
# SNAKEMAKEVERSION="7.24.2"
SNAKEMAKEVERSION="9.8.1"
CONDA_ACTIVATE=''
PATH_PREPEND=''
MODULE_LOAD=''
PLATFORM=$(get_platform)
PARTITION=''
EXTRA_SINGULARITY_BINDS=""
TEMP_DIR=""
REFS_DIR=""
CLUSTER_PROFILE="unknown"
DEFAULT_SHARED_SIF_DIR="/project/dremel_lab/workflows/singularity_images"
APPTAINER_SIF_DIR=""
APPTAINER_CACHE_DIR=""
APPTAINER_TMP_DIR=""
APPTAINER_PREFIX_ARG=""
SIF_DIR_OVERRIDE=""
if [ "$PLATFORM" == "shen" ]; then
  CLUSTER_PROFILE="rivanna"
  PARTITION="standard"
  EXTRA_SINGULARITY_BINDS=""
  CONDA_ACTIVATE='source /project/dremel_lab/scripts/.sh_common && mamba activate pipelines'
  # PY311_BIN=$(conda run -n py311 python -c "import sys; print(sys.executable.rsplit('/',1)[0])")
  PY311_BIN="/project/dremel_lab/conda/envs/py311/bin"
  # echo "PY311_BIN: $PY311_BIN"
  # make sure spooker is in the path
  PATH_PREPEND='export PATH="${PY311_BIN}:/standard/dremel_lab/scripts/bin:$PATH"'
  # echo $PATH
  # exit 1
  # eval $PATH_PREPEND
  # eval $CONDA_ACTIVATE
  # MODULE_LOAD="$CONDA_ACTIVATE && module load apptainer"
  # MODULE_LOAD="module load apptainer && module load snakemake"
  # MODULE_LOAD="$CONDA_ACTIVATE && module load apptainer && $PATH_PREPEND"
  MODULE_LOAD="module load apptainer"
  TEMP_DIR="/scratch/${USER}/"
  REFS_DIR="/standard/dremel_lab/workflows/reference_data/fasta_gtf/"
  KRAKEN2_DB="/standard/dremel_lab/workflows/reference_data/kraken2/kraken2_db"
else
  echo """WARNING: detected platform is $PLATFORM. Please edit the files in config/unknown/ & config.yaml for compatibility with your computing environment
    """
fi

# set defaults
HOST="hg38"
ADDITIVES="ERCC"
VIRUSES="NC_009333.1"
MANIFEST="${PIPELINE_HOME}/config/samples.tsv"
check_file $MANIFEST

# set variables
SCRIPTNAME="$0"
SCRIPTDIRNAME=$(readlink -f $(dirname $0))
SCRIPTBASENAME=$(basename $0)

##########################################################################################
# USAGE
##########################################################################################

function usage() { cat << EOF

##########################################################################################

Welcome to HAROLD
This is a basic RNAseq pipeline to get counts matrix for host + viral proteins.

HAROLD is only tested on Rivanna (https://www.rc.virginia.edu).
Please edit the files in config/unknown/ & config.yaml for compatibility with your
computing environment

##########################################################################################

HAROLD can be used to detect and count transcripts in hosts and viruses.

Here is the list of hosts and viruses that are currently supported:

HOSTS:
  * hg38          [Human]
  * mm39          [Mouse]

ADDITIVES:
  * ERCC          [External RNA Control Consortium sequences]
  * BAC16Insert   [insert from rKSHV.219-derived BAC clone of the full-length KSHV genome]

VIRUSES:
  * NC_007605.1   [Human gammaherpesvirus 4 (Epstein-Barr virus)]
  * NC_006273.2   [Human betaherpesvirus 5 (Cytomegalovirus )]
  * NC_001664.4   [Human betaherpesvirus 6A (HHV-6A)]
  * NC_000898.1   [Human betaherpesvirus 6B (HHV-6B)]
  * NC_001716.2   [Human betaherpesvirus 7 (HHV-7)]
  * NC_009333.1   [Human gammaherpesvirus 8 (KSHV)]
  * NC_045512.2   [Severe acute respiratory syndrome(SARS)-related coronavirus]
  * MN485971.1    [HIV from Belgium]
  * NC_001806.2   [Human alphaherpesvirus 1 (Herpes simplex virus type 1)](strain 17) (HSV-1)]
  * KT899744.1    [HSV-1 strain KOS]
  * MH636806.1    [MHV68 (Murine herpesvirus 68 strain WUMS)]

##########################################################################################

USAGE:
  harold -w/--workdir=<WORKDIR> -m/--runmode=<RUNMODE>

Required Arguments:
1.  WORKDIR     : [Type: String]: Absolute or relative path to the output folder with write permissions.

2.  RUNMODE     : [Type: String] Valid options:
    * init      : initialize workdir
    * dryrun    : dry run snakemake to generate DAG
    * run       : run with slurm
    * runlocal  : run without submitting to sbatch
    ADVANCED RUNMODES (use with caution!!)
    * unlock    : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING!
    * reconfig  : recreate config file in WORKDIR (debugging option) EDITS TO config.yaml WILL BE LOST!
    * reset     : DELETE workdir dir and re-init it (debugging option) EDITS TO ALL FILES IN WORKDIR WILL BE LOST!
    * printbinds: print singularity binds (paths)
    * local     : same as runlocal

Optional Arguments:

--host|-g       : supply host at command line. hg38 or mm39.                                            (--runmode=init only)
--additives|-a  : supply comma-separated list of additives at command line. ERCC or BAC16Insert or both (--runmode=init only)
--viruses|-v    : supply comma-separated list of viruses at command line                                (--runmode=init only)
--manifest|-s   : absolute path to samples.tsv. This will be copied to output folder                    (--runmode=init only)
--singcache|-c  : path for the Apptainer/Singularity cache (default: /scratch/\$USER/singularity/cache if available)
--sifdir|-i     : path for cached SIF images (default: /project/dremel_lab/workflows/singularity_images)
--help|-h       : print this help
--version|-V    : print HAROLD version and exit


Example commands:
  harold -w=/my/output/folder -m=init
  harold -w=/my/output/folder -m=dryrun
  harold -w=/my/output/folder -m=run

##########################################################################################

VersionInfo:
  python          : $PYTHONVERSION
  snakemake       : $SNAKEMAKEVERSION
  pipeline_home   : $PIPELINE_HOME
  git commit/tag  : $GIT_COMMIT_TAG
  pipeline version: $VERSION
  cluster_name    : $PLATFORM

##########################################################################################
EOF
}

##########################################################################################
# ERR
##########################################################################################

function err() { usage && cat <<< "
#
# ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR
#
  $@
#
# ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR ERROR
#
" && exit 1 1>&2; }

##########################################################################################
# INIT
##########################################################################################

function init() {

# create output folder
if [ -d $WORKDIR ];then err "Folder $WORKDIR already exists!"; fi
mkdir -p $WORKDIR

# copy config resources
cp -r ${PIPELINE_HOME}/config $WORKDIR/

echo "Editing config.yaml with the following parameters:"
echo ""

echo "Pipeline Dir: $PIPELINE_HOME"
echo "Git Commit/Tag: $GIT_COMMIT_TAG"
echo "Work Dir: $WORKDIR"
echo "Host: $HOST"
echo "Additives: $ADDITIVES"
echo "Viruses: $VIRUSES"
echo "Manifest: $MANIFEST"
echo "Temp Dir: $TEMP_DIR"
echo "Refs Dir: $REFS_DIR"
echo "Cluster Profile: $CLUSTER_PROFILE"
echo "Singularity Cache Dir: $SING_CACHE_DIR"
echo "Editing file $WORKDIR/config.yaml"
echo "..."

# copy config template and samples files
if [ ! -f $CONFIGFILE ];then
sed -e "
  s|PIPELINE_HOME|$PIPELINE_HOME|g;
  s|WORKDIR|$WORKDIR|g;
  s|HOST|$HOST|g;
  s|ADDITIVES|$ADDITIVES|g;
  s|VIRUSES|$VIRUSES|g;
  s|TEMP_DIR|$TEMP_DIR|g;
  s|REFS_DIR|$REFS_DIR|g;
  s|KRAKEN2_DB|$KRAKEN2_DB|g;
  s|CLUSTER_PROFILE|$CLUSTER_PROFILE|g
" ${PIPELINE_HOME}/config/config.yaml > $CONFIGFILE
else
  err "File $WORKDIR/config.yaml already exists!"
fi

echo "Completed writing $WORKDIR/config.yaml"
echo ""

if [ ! -f $WORKDIR/samples.tsv ];then
# copy manifest file ... follow symlink
cp -L $MANIFEST $WORKDIR/samples.tsv
fi

#create log and stats folders
if [ ! -d $WORKDIR/logs ]; then mkdir -p $WORKDIR/logs;echo "Logs Dir: $WORKDIR/logs";fi
if [ ! -d $WORKDIR/stats ];then mkdir -p $WORKDIR/stats;echo "Stats Dir: $WORKDIR/stats";fi

echo "Done Initializing $WORKDIR. !!"
echo "##########################################################################################"
echo " You can now edit the following files: "
echo " $WORKDIR/config.yaml "
echo " $WORKDIR/samples.tsv"
echo "##########################################################################################"

}

##########################################################################################
# CHECK ESSENTIAL FILES
##########################################################################################

function check_essential_files() {
  if [ ! -d $WORKDIR ];then err "Folder $WORKDIR does not exist!"; fi
  for f in config.yaml samples.tsv; do
    if [ ! -f $WORKDIR/$f ]; then err "Error: '${f}' file not found in workdir ... initialize first!";fi
  done
}


##########################################################################################
# RECONFIG ... recreate config.yaml and overwrite old version
##########################################################################################

function reconfig(){
  # rebuild config file and replace the config.yaml in the WORKDIR
  # this is only for dev purposes when new key-value pairs are being added to the config file
  check_essential_files
sed -e "
  s|PIPELINE_HOME|$PIPELINE_HOME|g;
  s|WORKDIR|$WORKDIR|g;
  s|HOST|$HOST|g;
  s|ADDITIVES|$ADDITIVES|g;
  s|VIRUSES|$VIRUSES|g;
  s|TEMP_DIR|$TEMP_DIR|g;
  s|REFS_DIR|$REFS_DIR|g;
  s|KRAKEN2_DB|$KRAKEN2_DB|g;
  s|CLUSTER_PROFILE|$CLUSTER_PROFILE|g
" ${PIPELINE_HOME}/config/config.yaml > $CONFIGFILE
  echo "$WORKDIR/config.yaml has been updated!"
}

##########################################################################################
# RECLUSTER ... update cluster related config files
##########################################################################################


function recluster(){

  # copy slurm config files to workdi
  for f in $(find ${PIPELINE_HOME}/config/ -type d -name "slurm*");do
    echo "Copying $f to $WORKDIR/config/"
    cp -r $f $WORKDIR/config/
  done
  echo "Done reclustering!"
}



# check whether required dependencies are in the path
function check_deps() {
  for dep in python snakemake singularity; do
    command -v $dep &> /dev/null || err "$dep not found in PATH"
  done
}

# load modules if available, or check whether they're in the path
function load_modules() {
  echo "Loading modules!!"
  echo "$MODULE_LOAD"
  eval $MODULE_LOAD
  module list
  which python
  which singularity
  which snakemake
  echo $PATH
  check_deps
}

##########################################################################################
# RUNCHECK ... check essential files and load required packages
##########################################################################################

function runcheck(){
  check_essential_files
  load_modules
  # CLUSTER_PROFILE="${WORKDIR}/${CLUSTER_PROFILE}"
  cd $WORKDIR
}

##########################################################################################
# DRYRUN ... also run automatically before actual run
##########################################################################################

function dryrun() {
  runcheck
  echo "Done Runcheck!"
  set_singularity_binds
  timestamp=$(date +"%y%m%d%H%M%S")
  nfiles=$(find ${WORKDIR} -maxdepth 1 -name "dryrun.*.log"|wc -l)
  if [ "$nfiles" != "0" ];then
    for f in $(ls ${WORKDIR}/dryrun.*.log);do
      mv $f ${WORKDIR}/stats/
    done
  fi
  run "--dry-run" | tee ${WORKDIR}/dryrun.${timestamp}.log
}

function touch() {
  runcheck
  timestamp=$(date +"%y%m%d%H%M%S")
  run "--touch" | tee ${WORKDIR}/touch.${timestamp}.log
}

##########################################################################################
# UNLOCK
##########################################################################################

function unlock() {
  runcheck
  run "--unlock"
}

##########################################################################################
# SET SINGULARITY BINDS ... bind required singularity folders appropriately
##########################################################################################

function set_singularity_binds() {
  binds=$( $PIPELINE_HOME/workflow/scripts/_find_singularity_bind_paths.py ${WORKDIR}/config.yaml ${WORKDIR}/samples.tsv)
  if [[ -z "${EXTRA_SINGULARITY_BINDS:-}" ]]; then
	SINGULARITY_BINDS="-B $binds"
  else
  	SINGULARITY_BINDS="-B $EXTRA_SINGULARITY_BINDS,$binds"
  fi
}
##########################################################################################
# PRINT SINGULARITY BINDS ... print bound singularity folders for debugging
##########################################################################################

function printbinds(){
  set_singularity_binds
  echo $SINGULARITY_BINDS
}

##########################################################################################
# RUNLOCAL ... run directly on local interactive node ... no submission to SLURM
##########################################################################################

function runlocal() {
  runcheck
  set_singularity_binds
  if [ "$SLURM_JOB_ID" == "" ];then err "runlocal can only be done on an interactive node"; exit 1; fi
  run "local"
}

##########################################################################################
# RUNSLURM ... submit head job to slurm which will spawn other jobs on SLURM
##########################################################################################

function runslurm() {
  runcheck
  set_singularity_binds
  timestamp=$(date +"%y%m%d%H%M%S")
  # Export PROFILE for use inside the head sbatch job (Snakemake expects this env var)
  EXPORT_PROFILE_CMD="export PROFILE=\"${WORKDIR}/config/${CLUSTER_PROFILE}\""

  # Create an sbatch wrapper that will run the snakemake head job on the scheduler.
  SBATCH_SCRIPT="${WORKDIR}/run_head_job.sbatch"
  # Use 2 CPUs, 40G memory, 3 days walltime as requested.
  # Include partition if set.
  if [[ -n "${PARTITION}" ]]; then
    PART_OPT="--partition=${PARTITION}"
  else
    PART_OPT=""
  fi

  cat > ${SBATCH_SCRIPT} <<-"SBATCH_EOF"
#!/bin/bash
# Auto-generated by HAROLD wrapper
#SBATCH --cpus-per-task=2
#SBATCH --mem=40G
#SBATCH --time=3-00:00:00
#SBATCH --account=dremel_lab
#SBATCH --job-name=harold_head_job
#SBATCH --output=__WORKDIR__/slurm-%j.out
__PART_OPTION__

set -euo pipefail

cd __WORKDIR__

# Export singularity cache dir if configured
__EXPORT_SING_CACHE_CMD__

# Export PROFILE so Snakemake/profile code can find the profile directory
__EXPORT_PROFILE_CMD__

# Load modules or conda if configured
__MODULE_LOAD_CMD__
__CONDA_ACTIVATE__

# Run snakemake (head job)
snakemake -s __SNAKEFILE__ --directory __WORKDIR__ -j 100 --verbose __APPTAINER_PREFIX__ --profile config/__CLUSTER_PROFILE__
SBATCH_EOF

  # Replace placeholders with actual values (safe expansion)
  sed -i "s|__WORKDIR__|${WORKDIR}|g" ${SBATCH_SCRIPT}
  sed -i "s|__SNAKEFILE__|${SNAKEFILE}|g" ${SBATCH_SCRIPT}
  sed -i "s|__CLUSTER_PROFILE__|${CLUSTER_PROFILE}|g" ${SBATCH_SCRIPT}
  sed -i "s|__CONDA_ACTIVATE__|${__CONDA_ACTIVATE__}|g" ${SBATCH_SCRIPT}
  if [[ -n "${APPTAINER_PREFIX_ARG}" ]]; then
    APPTAINER_PREFIX_ESCAPED=$(
      printf "%s" "${APPTAINER_PREFIX_ARG}" | sed -e 's/[&/]/\\&/g' -e 's/\\/\\\\/g' -e 's/"/\\"/g'
    )
    sed -i "s|__APPTAINER_PREFIX__|${APPTAINER_PREFIX_ESCAPED}|g" ${SBATCH_SCRIPT}
  else
    sed -i "s|__APPTAINER_PREFIX__||g" ${SBATCH_SCRIPT}
  fi
  if [[ -n "${PART_OPT}" ]]; then
    sed -i "s|__PART_OPTION__|#SBATCH ${PART_OPT}|g" ${SBATCH_SCRIPT}
  else
    sed -i "s|__PART_OPTION__||g" ${SBATCH_SCRIPT}
  fi

  # Export singularity cache dir command (may be empty)
  if [[ -n "${EXPORT_SING_CACHE_DIR_CMD:-}" ]]; then
    python - "$SBATCH_SCRIPT" <<'PY'
import os
import pathlib
import sys

path = pathlib.Path(sys.argv[1])
text = path.read_text()
replacement = os.environ["EXPORT_SING_CACHE_DIR_CMD"]
path.write_text(text.replace("__EXPORT_SING_CACHE_CMD__", replacement, 1))
PY
  else
    sed -i "s|__EXPORT_SING_CACHE_CMD__||g" ${SBATCH_SCRIPT}
  fi

  # Insert PROFILE export (may be empty)
  if [[ -n "${EXPORT_PROFILE_CMD:-}" ]]; then
    ESCAPED_PROFILE_CMD=$(printf "%s" "${EXPORT_PROFILE_CMD}" | sed 's|\\|\\\\|g')
    sed -i "s|__EXPORT_PROFILE_CMD__|${ESCAPED_PROFILE_CMD}|g" ${SBATCH_SCRIPT}
  else
    sed -i "s|__EXPORT_PROFILE_CMD__||g" ${SBATCH_SCRIPT}
  fi

  # MODULE_LOAD may contain commands to load modules/conda. Place it into script if set.
  if [[ -n "${MODULE_LOAD:-}" ]]; then
    ESCAPED_MODULE_LOAD=$(printf "%s" "${MODULE_LOAD}" | sed 's|\\|\\\\|g')
    sed -i "s|__MODULE_LOAD_CMD__|${ESCAPED_MODULE_LOAD}|g" ${SBATCH_SCRIPT}
  else
    sed -i "s|__MODULE_LOAD_CMD__||g" ${SBATCH_SCRIPT}
  fi

  # Submit the head job to Slurm and capture job id
  if command -v sbatch &> /dev/null; then
    JOBID=$(sbatch --parsable ${SBATCH_SCRIPT})
    echo "Submitted head job as sbatch job ${JOBID}. Output: ${WORKDIR}/slurm-${JOBID}.out"
  else
    err "sbatch not found in PATH; cannot submit head job to Slurm"
  fi

}

##########################################################################################
# CREATE RUNINFO ... create runinfo.yaml in workdir
##########################################################################################

function create_runinfo {
  modtime=$1
  if [ "$modtime" == "" ];then
   modtime=$(stat ${WORKDIR}/runinfo.yaml|grep Modify|awk '{print $2,$3}'|awk -F"." '{print $1}'|sed "s/ //g"|sed "s/-//g"|sed "s/://g")
  fi
  if [ -f ${WORKDIR}/runinfo.yaml ];then
    mv ${WORKDIR}/runinfo.yaml ${WORKDIR}/stats/runinfo.${modtime}.yaml
  fi
  echo "Pipeline Dir: $PIPELINE_HOME" > ${WORKDIR}/runinfo.yaml
  echo "Git Commit/Tag: $GIT_COMMIT_TAG" >> ${WORKDIR}/runinfo.yaml
  userlogin=$(whoami)
  if [[ `which finger 2>/dev/null` ]];then
	  username=$(finger $userlogin |grep ^Login | awk -F"Name: " '{print $2}');
  elif [[ `which getent 2>/dev/null` ]];then
    username=$(getent passwd $userlogin | awk -F":" '{print $5}' | awk '{$1=$1;print}');
  elif [[ `which lslogins 2>/dev/null` ]];then
	  username=$(lslogins -u $userlogin | grep ^Geco | awk -F": " '{print $2}' | awk '{$1=$1;print}');
  else username="";fi
  echo "Login: $userlogin" >> ${WORKDIR}/runinfo.yaml
  echo "Name: $username" >> ${WORKDIR}/runinfo.yaml
  g=$(groups)
  echo "Groups: $g" >> ${WORKDIR}/runinfo.yaml
  d=$(date)
  echo "Date/Time: $d" >> ${WORKDIR}/runinfo.yaml
}

##########################################################################################
# PRERUN CLEANUP ... get ready to run .. park old logs/stats etc.
##########################################################################################

function preruncleanup() {
  echo "Running..."

  # check initialization
  check_essential_files

  # export PROFILE
  export PROFILE="${WORKDIR}/config/${CLUSTER_PROFILE}"

  cd $WORKDIR
  modtime=""
  ## Archive previous run files
  # if [ -f ${WORKDIR}/snakemake.log ];then
  #   modtime=$(stat ${WORKDIR}/snakemake.log |grep Modify|awk '{print $2,$3}'|awk -F"." '{print $1}'|sed "s/ //g"|sed "s/-//g"|sed "s/://g")
  #   mv ${WORKDIR}/snakemake.log ${WORKDIR}/stats/snakemake.${modtime}.log
  #   if [ -f ${WORKDIR}/snakemake.log.HPC_summary.txt ];then
  #     mv ${WORKDIR}/snakemake.log.HPC_summary.txt ${WORKDIR}/stats/snakemake.${modtime}.log.HPC_summary.txt
  #   fi
  #   if [ -f ${WORKDIR}/report.html ];then
  #     mv ${WORKDIR}/report.html ${WORKDIR}/stats/snakemake.${modtime}.stats
  #   fi
  #   if [ -f ${WORKDIR}/snakemake.log.jobinfo ];then
  #     mv ${WORKDIR}/snakemake.log.jobinfo ${WORKDIR}/stats/snakemake.${modtime}.log.jobinfo
  #   fi
  # fi
  # nslurmouts=$(find ${WORKDIR} -maxdepth 1 -name "slurm-*.out" |wc -l)
  # if [ "$nslurmouts" != "0" ];then
  #   for f in $(ls ${WORKDIR}/slurm-*.out);do mv ${f} ${WORKDIR}/logs/;done
  # fi

  create_runinfo modtime

}

##########################################################################################
# RUN wrapper for all possible run's
# a. dryrun
# b. unlock
# c. local run
# d. slurm run, etc.
##########################################################################################

function run() {

  if [ "$1" == "local" ];then

    preruncleanup

    snakemake -s "$SNAKEFILE" \
      --directory "$WORKDIR" \
      -j 100 --verbose \
      ${APPTAINER_PREFIX_ARG} \
      --profile config/local

  elif [ "$1" == "slurm" ];then

    preruncleanup

    snakemake -s "$SNAKEFILE" \
      --directory "$WORKDIR" \
      -j 100 --verbose \
      ${APPTAINER_PREFIX_ARG} \
      --profile "config/${CLUSTER_PROFILE}"

  elif [ "$1" == "--touch" ];then

    snakemake "$1" -s "$SNAKEFILE" \
      --directory "$WORKDIR" \
      ${APPTAINER_PREFIX_ARG} \
      --cores 1

  else # dry-run and unlock

    preruncleanup

    snakemake -s "$SNAKEFILE" \
      --directory "$WORKDIR" \
      -j 100 --verbose \
      ${APPTAINER_PREFIX_ARG} \
      --profile "config/${CLUSTER_PROFILE}" \
      "$1"

  fi

}

##########################################################################################
# RESET ... delete workdir and then initialize
##########################################################################################

function reset() {
  #delete the workdir and re-initialize it
  echo "Working Dir: $WORKDIR"
  if [ ! -d $WORKDIR ];then err "Folder $WORKDIR does not exist!";fi
  echo "Deleting $WORKDIR"
  rm -rf $WORKDIR
  echo "Re-Initializing $WORKDIR"
  init
}

##########################################################################################
# MAIN ... command line argument parsing
##########################################################################################

function main(){

  if [ $# -eq 0 ]; then usage; exit 1; fi

  allargs="$@"

  for i in "$@"
  do
  case $i in
      -m=*|--runmode=*)
        RUNMODE="${i#*=}"
      ;;
      -w=*|--workdir=*)
        WORKDIR="${i#*=}"
      ;;
      -c=*|--singcache=*)
        SING_CACHE_DIR="${i#*=}"
      ;;
      -i=*|--sifdir=*)
        SIF_DIR_OVERRIDE="${i#*=}"
      ;;
      -g=*|--host=*)
        HOST="${i#*=}"
      ;;
      -a=*|--additives=*)
        ADDITIVES="${i#*=}"
      ;;
      -v=*|--viruses=*)
        VIRUSES="${i#*=}"
      ;;
      -s=*|--manifest=*)
        MANIFEST="${i#*=}"
        if [ ! -f $MANIFEST ];then err "File $MANIFEST does NOT exist!";fi
      ;;
      -h|--help)
        usage && exit 0;
      ;;
      -V|--version)
        echo "$VERSION"
        exit 0
      ;;
      *)
        err "Unknown argument $i!"    # unknown option
      ;;
  esac
  done

  WORKDIR=$(readlink -f $WORKDIR)
  echo "Working Dir: $WORKDIR"
  CONFIGFILE="${WORKDIR}/config.yaml"

  SCRATCH_ROOT="${SCRATCH:-/scratch/$USER}"
  SCRATCH_FALLBACK="${WORKDIR}/.harold_runtime"
  if [[ ! -d "$SCRATCH_ROOT" ]]; then
    mkdir -p "$SCRATCH_ROOT" 2>/dev/null || SCRATCH_ROOT="$SCRATCH_FALLBACK"
  fi

  SINGULARITY_RUNTIME_ROOT="${SCRATCH_ROOT}/singularity"
  if [[ -z "$SING_CACHE_DIR" ]]; then
    if [[ -d "$SCRATCH_ROOT" ]]; then
      SING_CACHE_DIR="${SINGULARITY_RUNTIME_ROOT}/cache"
    elif [[ -d "/data/$USER" ]]; then
      SING_CACHE_DIR="/data/$USER/singularity/cache"
    else
      SING_CACHE_DIR="${WORKDIR}/.singularity/cache"
    fi
    echo "apptainer cache dir (--singcache) is not set, using ${SING_CACHE_DIR}"
  fi
  if [[ -n "${SIF_DIR_OVERRIDE:-}" ]]; then
    APPTAINER_SIF_DIR="$SIF_DIR_OVERRIDE"
  else
    APPTAINER_SIF_DIR="$DEFAULT_SHARED_SIF_DIR"
  fi
  if [[ ! -d "$APPTAINER_SIF_DIR" ]]; then
    if ! mkdir -p "$APPTAINER_SIF_DIR" 2>/dev/null; then
      echo "WARNING: Unable to access ${APPTAINER_SIF_DIR}; falling back to ${SINGULARITY_RUNTIME_ROOT}/sif"
      APPTAINER_SIF_DIR="${SINGULARITY_RUNTIME_ROOT}/sif"
      mkdir -p "$APPTAINER_SIF_DIR"
    fi
  fi
  APPTAINER_TMP_DIR="${SINGULARITY_RUNTIME_ROOT}/tmp"

  mkdir -p "$SING_CACHE_DIR" "$APPTAINER_TMP_DIR"

  APPTAINER_SIF_DIR=$(readlink -f "$APPTAINER_SIF_DIR")
  APPTAINER_CACHE_DIR=$(readlink -f "$SING_CACHE_DIR")
  APPTAINER_TMP_DIR=$(readlink -f "$APPTAINER_TMP_DIR")

  if [[ -n "$APPTAINER_SIF_DIR" ]]; then
    APPTAINER_PREFIX_ARG="--apptainer-prefix=${APPTAINER_SIF_DIR}"
  else
    APPTAINER_PREFIX_ARG=""
  fi

  export APPTAINER_CACHEDIR="${APPTAINER_CACHE_DIR}"
  export SINGULARITY_CACHEDIR="${APPTAINER_CACHE_DIR}"
  export APPTAINER_TMPDIR="${APPTAINER_TMP_DIR}"
  export SINGULARITY_TMPDIR="${APPTAINER_TMP_DIR}"
  export APPTAINER_PULLDIR="${APPTAINER_SIF_DIR}"
  export TMPDIR="${APPTAINER_TMP_DIR}"
  export APPTAINER_SIF_DIR

  EXPORT_SING_CACHE_DIR_CMD=$(
    cat <<EOF
export APPTAINER_CACHEDIR="${APPTAINER_CACHE_DIR}"
export SINGULARITY_CACHEDIR="${APPTAINER_CACHE_DIR}"
export APPTAINER_TMPDIR="${APPTAINER_TMP_DIR}"
export SINGULARITY_TMPDIR="${APPTAINER_TMP_DIR}"
export APPTAINER_PULLDIR="${APPTAINER_SIF_DIR}"
export TMPDIR="${APPTAINER_TMP_DIR}"
export APPTAINER_SIF_DIR="${APPTAINER_SIF_DIR}"
EOF
  )
  export EXPORT_SING_CACHE_DIR_CMD

  if [[ "$APPTAINER_SIF_DIR" == "$DEFAULT_SHARED_SIF_DIR" ]]; then
    warn_missing_shared_sifs "$CONFIGFILE" "$APPTAINER_SIF_DIR"
  fi

  case $RUNMODE in
    init) init && exit 0;;
    dryrun) dryrun && exit 0;;
    unlock) unlock && exit 0;;
    run) runslurm && exit 0;;
    runlocal) runlocal && exit 0;;
    reset) reset && exit 0;;
    touch) touch && exit 0;;
    dry) dryrun && exit 0;;                      # hidden option
    local) runlocal && exit 0;;                  # hidden option
    reconfig) reconfig && exit 0;;               # hidden option for debugging
    recluster) recluster && exit 0;;               # hidden option for debugging
    printbinds) printbinds && exit 0;;           # hidden option
    help) usage && exit 0;;                      # print help
    *) err "Unknown RUNMODE \"$RUNMODE\"";;
  esac
}

##########################################################################################
# run main!
##########################################################################################

main "$@"
